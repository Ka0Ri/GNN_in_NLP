{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWn5yzT0LOzH",
        "outputId": "d377126a-3b3e-4f38-d9e7-e86a1ac54e02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.12.0\n"
          ]
        }
      ],
      "source": [
        "# Install required packages.\n",
        "import os\n",
        "import torch\n",
        "os.environ['TORCH'] = torch.__version__\n",
        "print(torch.__version__)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KDy46FIQ6OWN"
      },
      "source": [
        "# Customizing Aggregations within Message Passing with `torch_geometric.nn.aggr`\n",
        "\n",
        "Aggregation functions play an important role in the message passing framework and the readout function when implementing GNNs. Many works in the GNN literature ([Hamilton et al. (2017)](https://cs.stanford.edu/~jure/pubs/graphsage-nips17.pdf), [Xu et al. (2018)](https://arxiv.org/abs/1810.00826), [Corso et al. (2020)](https://proceedings.neurips.cc/paper/2020/file/99cad265a1768cc2dd013f0e740300ae-Paper.pdf), [Li et al. (2020)](https://arxiv.org/abs/2006.07739)), demonstrate that the choice of aggregation functions contributes significantly to the performance of GNN models. In particular, the performance of GNNs with different aggregation functions differs when applied to distinct tasks and datasets. Recent works also show that using multiple aggregations ([Corso et al. (2020)](https://proceedings.neurips.cc/paper/2020/file/99cad265a1768cc2dd013f0e740300ae-Paper.pdf)) and learnable aggregations ([Li et al. (2020)](https://arxiv.org/abs/2006.07739)) can potentially gain substantial improvements. To facilitate experimentation with these different aggregation schemes and unify concepts of aggregation within GNNs across both [`MessagePassing`](https://github.com/pyg-team/pytorch_geometric/blob/master/torch_geometric/nn/conv/message_passing.py) and [global readouts](https://github.com/pyg-team/pytorch_geometric/tree/master/torch_geometric/nn/glob), we provide **modular and re-usable aggregations** in the newly defined `torch_geometric.nn.aggr.*` package. Unifying these concepts also helps us to perform optimization and specialized implementations in a single place. In the new integration, the following functionality is applicable:\n",
        "\n",
        "```python\n",
        "# Original interface with string type as aggregation argument\n",
        "class MyConv(MessagePassing):\n",
        "    def __init__(self):\n",
        "        super().__init__(aggr=\"mean\")\n",
        "\n",
        "# Use a single aggregation module as aggregation argument\n",
        "class MyConv(MessagePassing):\n",
        "    def __init__(self):\n",
        "        super().__init__(aggr=MeanAggregation())\n",
        "\n",
        "# Use a list of aggregation strings as aggregation argument\n",
        "class MyConv(MessagePassing):\n",
        "    def __init__(self):\n",
        "        super().__init__(aggr=['mean', 'max', 'sum', 'std', 'var'])\n",
        "\n",
        "# Use a list of aggregation modules as aggregation argument\n",
        "class MyConv(MessagePassing):\n",
        "    def __init__(self):\n",
        "        super().__init__(aggr=[\n",
        "          MeanAggregation(),\n",
        "          MaxAggregation(),\n",
        "          SumAggregation(),\n",
        "          StdAggregation(),\n",
        "          VarAggregation(),\n",
        "          ])\n",
        "\n",
        "# Use a list of mixed modules and strings as aggregation argument\n",
        "class MyConv(MessagePassing):\n",
        "    def __init__(self):\n",
        "        super().__init__(aggr=[\n",
        "          'mean',\n",
        "          MaxAggregation(),\n",
        "          'sum',\n",
        "          StdAggregation(),\n",
        "          'var',\n",
        "          ])\n",
        "\n",
        "# Define multiple learnable aggregations with keyword arguments\n",
        "class MyConv(MessagePassing):\n",
        "    def __init__(self):\n",
        "        super().__init__(aggr=['softmax', 'softmax', 'softmax'],\n",
        "        aggr_kwargs = dict(aggrs_kwargs=[\n",
        "                            dict(t=0.1, learn=True),\n",
        "                            dict(t=1, learn=True),\n",
        "                            dict(t=10, learn=True)]))\n",
        "\n",
        "# Define multiple aggregations with `MultiAggregation` module\n",
        "class MyConv(MessagePassing):\n",
        "    def __init__(self):\n",
        "        super().__init__(aggr=MultiAggregation([\n",
        "          SoftmaxAggregation(t=0.1, learn=True),\n",
        "          SoftmaxAggregation(t=1, learn=True),\n",
        "          SoftmaxAggregation(t=10, learn=True)]))\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3W4IfAWgSXVy"
      },
      "source": [
        "In this tutorial, we explore the new aggregation package with `SAGEConv` ([Hamilton et al. (2017)](https://cs.stanford.edu/~jure/pubs/graphsage-nips17.pdf)) and `ClusterLoader` ([Chiang et al. (2019)](https://arxiv.org/abs/1905.07953)) and showcase on the `PubMed` graph from the `Planetoid` node classification benchmark suite ([Yang et al. (2016)](https://arxiv.org/abs/1603.08861))."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_s25N9oyBIy"
      },
      "source": [
        "## Loading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eBN2pGDueDpZ",
        "outputId": "5a53b10d-181a-49bc-adf9-3ece6c226a33"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Dataset: PubMed():\n",
            "==================\n",
            "Number of graphs: 1\n",
            "Number of features: 500\n",
            "Number of classes: 3\n",
            "\n",
            "Data(x=[19717, 500], edge_index=[2, 88648], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717])\n",
            "===============================================================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Computing METIS partitioning...\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch_geometric.datasets import Planetoid\n",
        "from torch_geometric.transforms import NormalizeFeatures\n",
        "\n",
        "dataset = Planetoid(root='data/Planetoid', name='PubMed', transform=NormalizeFeatures())\n",
        "\n",
        "print()\n",
        "print(f'Dataset: {dataset}:')\n",
        "print('==================')\n",
        "print(f'Number of graphs: {len(dataset)}')\n",
        "print(f'Number of features: {dataset.num_features}')\n",
        "print(f'Number of classes: {dataset.num_classes}')\n",
        "\n",
        "data = dataset[0]  # Get the first graph object.\n",
        "\n",
        "print()\n",
        "print(data)\n",
        "print('===============================================================================================================')\n",
        "\n",
        "from torch_geometric.loader import ClusterData, ClusterLoader\n",
        "\n",
        "torch.manual_seed(12345)\n",
        "cluster_data = ClusterData(data, num_parts=128)  # 1. Create subgraphs.\n",
        "train_loader = ClusterLoader(cluster_data, batch_size=32, shuffle=True)  # 2. Stochastic partioning scheme."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tbHL1x7fzjeR"
      },
      "source": [
        "## Define train, test and run functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "5pJQ7brC7VzC"
      },
      "outputs": [],
      "source": [
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "def train(model):\n",
        "  model.train()\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
        "  for sub_data in train_loader:  # Iterate over each mini-batch.\n",
        "    optimizer.zero_grad()  # Clear gradients.\n",
        "    out = model(sub_data.x, sub_data.edge_index)  # Perform a single forward pass.\n",
        "    loss = criterion(out[sub_data.train_mask], sub_data.y[sub_data.train_mask])  # Compute the loss solely based on the training nodes.\n",
        "    loss.backward()  # Derive gradients.\n",
        "    optimizer.step()  # Update parameters based on gradients.\n",
        "\n",
        "def test(model):\n",
        "  model.eval()\n",
        "  out = model(data.x, data.edge_index)\n",
        "  pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
        "  \n",
        "  accs = []\n",
        "  for mask in [data.train_mask, data.val_mask, data.test_mask]:\n",
        "    correct = pred[mask] == data.y[mask]  # Check against ground-truth labels.\n",
        "    accs.append(int(correct.sum()) / int(mask.sum()))  # Derive ratio of correct predictions.\n",
        "  return accs\n",
        "\n",
        "def run(model, epochs=5):\n",
        "  for epoch in range(1, epochs):\n",
        "    loss = train(model)\n",
        "    train_acc, val_acc, test_acc = test(model)\n",
        "    print(f'Epoch: {epoch:03d}, Train: {train_acc:.4f}, Val Acc: {val_acc:.4f}, Test Acc: {test_acc:.4f}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjgqVC960FT2"
      },
      "source": [
        "## Training GNNs with `torch_geometric.nn.aggr` package"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALbxt90iftTm"
      },
      "source": [
        "### Define a GNN class\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "dhGCq1KbAxAX"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'torch_geometric.nn.aggr'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32m/home/vips/share/Vu/GNN_in_NLP/7_Aggregation_Package.ipynb Cell 10\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a223136382e3133312e3135342e323236222c2275736572223a2276697073222c22706f7274223a363230307d/home/vips/share/Vu/GNN_in_NLP/7_Aggregation_Package.ipynb#ch0000009vscode-remote?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfunctional\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mF\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a223136382e3133312e3135342e323236222c2275736572223a2276697073222c22706f7274223a363230307d/home/vips/share/Vu/GNN_in_NLP/7_Aggregation_Package.ipynb#ch0000009vscode-remote?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch_geometric\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnn\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a223136382e3133312e3135342e323236222c2275736572223a2276697073222c22706f7274223a363230307d/home/vips/share/Vu/GNN_in_NLP/7_Aggregation_Package.ipynb#ch0000009vscode-remote?line=3'>4</a>\u001b[0m     SAGEConv,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a223136382e3133312e3135342e323236222c2275736572223a2276697073222c22706f7274223a363230307d/home/vips/share/Vu/GNN_in_NLP/7_Aggregation_Package.ipynb#ch0000009vscode-remote?line=4'>5</a>\u001b[0m    \n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a223136382e3133312e3135342e323236222c2275736572223a2276697073222c22706f7274223a363230307d/home/vips/share/Vu/GNN_in_NLP/7_Aggregation_Package.ipynb#ch0000009vscode-remote?line=5'>6</a>\u001b[0m )\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a223136382e3133312e3135342e323236222c2275736572223a2276697073222c22706f7274223a363230307d/home/vips/share/Vu/GNN_in_NLP/7_Aggregation_Package.ipynb#ch0000009vscode-remote?line=6'>7</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch_geometric\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39maggr\u001b[39;00m \u001b[39mimport\u001b[39;00m Aggregation, MultiAggregation\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a223136382e3133312e3135342e323236222c2275736572223a2276697073222c22706f7274223a363230307d/home/vips/share/Vu/GNN_in_NLP/7_Aggregation_Package.ipynb#ch0000009vscode-remote?line=8'>9</a>\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mGNN\u001b[39;00m(torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mModule):\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a223136382e3133312e3135342e323236222c2275736572223a2276697073222c22706f7274223a363230307d/home/vips/share/Vu/GNN_in_NLP/7_Aggregation_Package.ipynb#ch0000009vscode-remote?line=9'>10</a>\u001b[0m   \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, hidden_channels, aggr\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmean\u001b[39m\u001b[39m'\u001b[39m, aggr_kwargs\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch_geometric.nn.aggr'"
          ]
        }
      ],
      "source": [
        "import copy\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import (\n",
        "    SAGEConv,\n",
        "   \n",
        ")\n",
        "from torch_geometric.nn.aggr import Aggregation, MultiAggregation\n",
        "\n",
        "class GNN(torch.nn.Module):\n",
        "  def __init__(self, hidden_channels, aggr='mean', aggr_kwargs=None):\n",
        "      super(GNN, self).__init__()\n",
        "      torch.manual_seed(12345)\n",
        "      if isinstance(aggr, list):\n",
        "        num_aggrs = len(aggr)\n",
        "      elif isinstance(aggr, str):\n",
        "        num_aggrs = 1\n",
        "      elif isinstance(aggr, MultiAggregation):\n",
        "        num_aggrs = len(aggr.aggrs)\n",
        "      elif isinstance(aggr, Aggregation):\n",
        "        num_aggrs = 1\n",
        "      else:\n",
        "        raise KeyError(f\"Unknown aggr: {aggr}\")\n",
        "      conv1_aggr, conv2_aggr = aggr, copy.deepcopy(aggr)\n",
        "      self.conv1 = SAGEConv([dataset.num_node_features * num_aggrs, dataset.num_node_features],\n",
        "                            hidden_channels,\n",
        "                            aggr=conv1_aggr,\n",
        "                            aggr_kwargs=aggr_kwargs)\n",
        "      self.conv2 = SAGEConv([hidden_channels * num_aggrs, hidden_channels],\n",
        "                            dataset.num_classes,\n",
        "                            aggr=conv2_aggr,\n",
        "                            aggr_kwargs=aggr_kwargs)\n",
        "\n",
        "  def forward(self, x, edge_index):\n",
        "      x = self.conv1(x, edge_index)\n",
        "      x = x.relu()\n",
        "      x = F.dropout(x, p=0.5, training=self.training)\n",
        "      x = self.conv2(x, edge_index)\n",
        "      return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZIg70vDmLO5V"
      },
      "source": [
        "### Original interface with string type as aggregation argument"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GuRdM5VjDIAv",
        "outputId": "4b6c8991-59d0-4d3e-dcae-389b2cdaf0a9"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'GNN' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m/home/vips/share/Vu/GNN_in_NLP/7_Aggregation_Package.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a223136382e3133312e3135342e323236222c2275736572223a2276697073222c22706f7274223a363230307d/home/vips/share/Vu/GNN_in_NLP/7_Aggregation_Package.ipynb#ch0000011vscode-remote?line=0'>1</a>\u001b[0m model \u001b[39m=\u001b[39m GNN(\u001b[39m16\u001b[39m, aggr\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmean\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a223136382e3133312e3135342e323236222c2275736572223a2276697073222c22706f7274223a363230307d/home/vips/share/Vu/GNN_in_NLP/7_Aggregation_Package.ipynb#ch0000011vscode-remote?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(model)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a223136382e3133312e3135342e323236222c2275736572223a2276697073222c22706f7274223a363230307d/home/vips/share/Vu/GNN_in_NLP/7_Aggregation_Package.ipynb#ch0000011vscode-remote?line=2'>3</a>\u001b[0m optimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mAdam(model\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39m\u001b[39m0.01\u001b[39m, weight_decay\u001b[39m=\u001b[39m\u001b[39m5e-4\u001b[39m)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'GNN' is not defined"
          ]
        }
      ],
      "source": [
        "model = GNN(16, aggr='mean')\n",
        "print(model)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
        "run(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-e0uXR9Ldcf"
      },
      "source": [
        "### Use a single aggregation module as aggregation argument"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C66kK8wfCSnF",
        "outputId": "9b62f6a4-80cb-4071-fc78-c94d61bf8d31"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GNN(\n",
            "  (conv1): SAGEConv([500, 500], 16, aggr=MeanAggregation())\n",
            "  (conv2): SAGEConv([16, 16], 3, aggr=MeanAggregation())\n",
            ")\n",
            "Epoch: 001, Train: 0.3333, Val Acc: 0.3880, Test Acc: 0.4130\n",
            "Epoch: 002, Train: 0.3333, Val Acc: 0.3880, Test Acc: 0.4130\n",
            "Epoch: 003, Train: 0.3333, Val Acc: 0.3880, Test Acc: 0.4130\n",
            "Epoch: 004, Train: 0.6667, Val Acc: 0.5060, Test Acc: 0.5430\n"
          ]
        }
      ],
      "source": [
        "model = GNN(16, aggr=MeanAggregation())\n",
        "print(model)\n",
        "run(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yslL-7_vLmaD"
      },
      "source": [
        "### Use a list of aggregation strings as aggregation argument"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ANwoZ7Z-aau",
        "outputId": "2da58c02-24ec-453f-a444-df78cce38c32"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GNN(\n",
            "  (conv1): SAGEConv([2500, 500], 16, aggr=['mean', 'max', 'sum', 'std', 'var'])\n",
            "  (conv2): SAGEConv([80, 16], 3, aggr=['mean', 'max', 'sum', 'std', 'var'])\n",
            ")\n",
            "Epoch: 001, Train: 0.5000, Val Acc: 0.3640, Test Acc: 0.3550\n",
            "Epoch: 002, Train: 0.7833, Val Acc: 0.6120, Test Acc: 0.6160\n",
            "Epoch: 003, Train: 0.8167, Val Acc: 0.5680, Test Acc: 0.5350\n",
            "Epoch: 004, Train: 0.8667, Val Acc: 0.7120, Test Acc: 0.6940\n"
          ]
        }
      ],
      "source": [
        "model = GNN(16, aggr=['mean', 'max', 'sum', 'std', 'var'])\n",
        "print(model)\n",
        "run(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cykfCUUhLojw"
      },
      "source": [
        "### Use a list of aggregation modules as aggregation argument"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0M1UdXiOGpuC",
        "outputId": "bc0b3e79-7b61-4247-bde3-ba49375c8bea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GNN(\n",
            "  (conv1): SAGEConv([2500, 500], 16, aggr=['MeanAggregation()', 'MaxAggregation()', 'SumAggregation()', 'StdAggregation()', 'VarAggregation()'])\n",
            "  (conv2): SAGEConv([80, 16], 3, aggr=['MeanAggregation()', 'MaxAggregation()', 'SumAggregation()', 'StdAggregation()', 'VarAggregation()'])\n",
            ")\n",
            "Epoch: 001, Train: 0.5000, Val Acc: 0.3640, Test Acc: 0.3550\n",
            "Epoch: 002, Train: 0.7833, Val Acc: 0.6120, Test Acc: 0.6160\n",
            "Epoch: 003, Train: 0.8167, Val Acc: 0.5680, Test Acc: 0.5350\n",
            "Epoch: 004, Train: 0.8667, Val Acc: 0.7120, Test Acc: 0.6940\n"
          ]
        }
      ],
      "source": [
        "model = GNN(16, aggr=[\n",
        "                      MeanAggregation(),\n",
        "                      MaxAggregation(),\n",
        "                      SumAggregation(),\n",
        "                      StdAggregation(),\n",
        "                      VarAggregation(),\n",
        "                      ])\n",
        "print(model)\n",
        "run(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xf2Qb_ydL2w2"
      },
      "source": [
        "### Use a list of mixed modules and strings as aggregation argument"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0uLPbAHIHvYr",
        "outputId": "caeaf3dd-0c90-4a17-e573-dd7fbf62ade1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GNN(\n",
            "  (conv1): SAGEConv([2500, 500], 16, aggr=['mean', 'MaxAggregation()', 'sum', 'StdAggregation()', 'var'])\n",
            "  (conv2): SAGEConv([80, 16], 3, aggr=['mean', 'MaxAggregation()', 'sum', 'StdAggregation()', 'var'])\n",
            ")\n",
            "Epoch: 001, Train: 0.5000, Val Acc: 0.3640, Test Acc: 0.3550\n",
            "Epoch: 002, Train: 0.7833, Val Acc: 0.6120, Test Acc: 0.6160\n",
            "Epoch: 003, Train: 0.8167, Val Acc: 0.5680, Test Acc: 0.5350\n",
            "Epoch: 004, Train: 0.8667, Val Acc: 0.7120, Test Acc: 0.6940\n"
          ]
        }
      ],
      "source": [
        "model = GNN(16, aggr=[\n",
        "                      'mean',\n",
        "                      MaxAggregation(),\n",
        "                      'sum',\n",
        "                      StdAggregation(),\n",
        "                      'var',\n",
        "                      ])\n",
        "print(model)\n",
        "run(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nfl9ZA9XL8Ck"
      },
      "source": [
        "### Define multiple learnable aggregations with keyword arguments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tk4wsJSP-O5G",
        "outputId": "ed02313f-731f-4b8b-e921-2a7279d6ccf9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GNN(\n",
            "  (conv1): SAGEConv([1500, 500], 16, aggr=['softmax', 'softmax', 'softmax'])\n",
            "  (conv2): SAGEConv([48, 16], 3, aggr=['softmax', 'softmax', 'softmax'])\n",
            ")\n",
            "Epoch: 001, Train: 0.8500, Val Acc: 0.6980, Test Acc: 0.7010\n",
            "Epoch: 002, Train: 0.9333, Val Acc: 0.6420, Test Acc: 0.6600\n",
            "Epoch: 003, Train: 0.7500, Val Acc: 0.6260, Test Acc: 0.6520\n",
            "Epoch: 004, Train: 0.9333, Val Acc: 0.7580, Test Acc: 0.7430\n"
          ]
        }
      ],
      "source": [
        "aggr = ['softmax', 'softmax', 'softmax']\n",
        "aggrs_kwargs = [dict(t=0.1, learn=True),\n",
        "               dict(t=1, learn=True),\n",
        "               dict(t=10, learn=True)]\n",
        "model = GNN(16, aggr=aggr, aggr_kwargs=dict(aggrs_kwargs=aggrs_kwargs))\n",
        "print(model)\n",
        "run(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFw0MMx3L-rd"
      },
      "source": [
        "### Define multiple aggregations with `MultiAggregation` module"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6iUX1IvICOW",
        "outputId": "045cbb11-ce78-4945-aed3-4027bdc952aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GNN(\n",
            "  (conv1): SAGEConv([1500, 500], 16, aggr=MultiAggregation([\n",
            "    SoftmaxAggregation(learn=True),\n",
            "    SoftmaxAggregation(learn=True),\n",
            "    SoftmaxAggregation(learn=True)\n",
            "  ], mode=cat))\n",
            "  (conv2): SAGEConv([48, 16], 3, aggr=MultiAggregation([\n",
            "    SoftmaxAggregation(learn=True),\n",
            "    SoftmaxAggregation(learn=True),\n",
            "    SoftmaxAggregation(learn=True)\n",
            "  ], mode=cat))\n",
            ")\n",
            "Epoch: 001, Train: 0.8500, Val Acc: 0.6980, Test Acc: 0.7010\n",
            "Epoch: 002, Train: 0.9333, Val Acc: 0.6420, Test Acc: 0.6600\n",
            "Epoch: 003, Train: 0.7500, Val Acc: 0.6260, Test Acc: 0.6520\n",
            "Epoch: 004, Train: 0.9333, Val Acc: 0.7580, Test Acc: 0.7430\n"
          ]
        }
      ],
      "source": [
        "aggr = MultiAggregation([SoftmaxAggregation(t=0.1, learn=True),\n",
        "                         SoftmaxAggregation(t=1, learn=True),\n",
        "                         SoftmaxAggregation(t=10, learn=True)])       \n",
        "model = GNN(16, aggr=aggr)\n",
        "print(model)\n",
        "run(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDOmdUe0C3U1"
      },
      "source": [
        "## Conclusion\n",
        "\n",
        "In this tutorial, you have been presented with the new `torch_geometric.nn.aggr` package which provides a flexible interface to experiment with different aggregation functions with your message passing convolutions and unifies aggregation within GNNs across [`MessagePassing`](https://github.com/pyg-team/pytorch_geometric/blob/master/torch_geometric/nn/conv/message_passing.py) and [global readouts](https://github.com/pyg-team/pytorch_geometric/tree/master/torch_geometric/nn/glob). This new abstraction also makes designing new type of aggregation function easier. Now, you can create your own aggregation function with the base `Aggregation` class:\n",
        "\n",
        "```python\n",
        "class MyAggregation(Aggregation):\n",
        "    def __init__(self, ...):\n",
        "      ...\n",
        "\n",
        "    def forward(self, x: Tensor, index: Optional[Tensor] = None,\n",
        "                ptr: Optional[Tensor] = None, dim_size: Optional[int] = None,\n",
        "                dim: int = -2) -> Tensor:\n",
        "      ...\n",
        "```\n",
        "\n",
        "*Have fun!*"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "7. Aggregation Package.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.10.4 ('GNN')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "e215ceb6bc66c02176aac9a16ef7bdd77eb4405484a4a652fefcacf52fac4f29"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
